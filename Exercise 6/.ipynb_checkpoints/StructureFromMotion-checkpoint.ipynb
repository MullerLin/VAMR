{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b480538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0757f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearTriangulation(p1, p2, M1, M2):\n",
    "    \"\"\" Linear Triangulation\n",
    "     Input:\n",
    "      - p1 np.ndarray(3, N): homogeneous coordinates of points in image 1\n",
    "      - p2 np.ndarray(3, N): homogeneous coordinates of points in image 2\n",
    "      - M1 np.ndarray(3, 4): projection matrix corresponding to first image\n",
    "      - M2 np.ndarray(3, 4): projection matrix corresponding to second image\n",
    "\n",
    "     Output:\n",
    "      - P np.ndarray(4, N): homogeneous coordinates of 3-D points\n",
    "    \"\"\"\n",
    "    p_size = p1.shape[1]\n",
    "    P_est = np.ones([p_size,4])\n",
    "    for i in range (p_size):\n",
    "        temp_p1_x = cross2Matrix(p1[:,i].squeeze())\n",
    "        temp_p2_x = cross2Matrix(p2[:,i].squeeze())\n",
    "        temp_A = np.r_[temp_p1_x@M1, temp_p2_x@M2]\n",
    "        _,_, VT = np.linalg.svd(temp_A,full_matrices=True)\n",
    "        P_est[i,]  = VT.T[:,-1] / VT.T[3,-1]   \n",
    "\n",
    "    \n",
    "    return P_est.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926af037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise2DPts(pts):\n",
    "    \"\"\"  normalises 2D homogeneous points\n",
    "\n",
    "     Function translates and normalises a set of 2D homogeneous points\n",
    "     so that their centroid is at the origin and their mean distance from\n",
    "     the origin is sqrt(2).\n",
    "\n",
    "     Usage:   [pts_tilde, T] = normalise2dpts(pts)\n",
    "\n",
    "     Argument:\n",
    "       pts -  3xN array of 2D homogeneous coordinates\n",
    "\n",
    "     Returns:\n",
    "       pts_tilde -  3xN array of transformed 2D homogeneous coordinates.\n",
    "       T         -  The 3x3 transformation matrix, pts_tilde = T*pts\n",
    "    \"\"\"\n",
    "    \n",
    "    pts_E = pts/pts[2:,]\n",
    "    miu = np.mean(pts_E[:2,:], axis = 1)\n",
    "    \n",
    "    pts_dis = pts_E[:2,:].T - miu\n",
    "    sigma = np.sqrt(np.mean(np.sum(pts_dis**2, axis = 1)))\n",
    "    s = np.sqrt(2) / sigma\n",
    "    T = np.array([\n",
    "    [s, 0, -s * miu[0]],\n",
    "    [0, s, -s * miu[1]],\n",
    "    [0, 0, 1]])\n",
    "    pts_tilde = T @ pts_E\n",
    "    return pts_tilde, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7cbe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fundamentalEightPoint(p1, p2):\n",
    "    \"\"\" The 8-point algorithm for the estimation of the fundamental matrix F\n",
    "\n",
    "     The eight-point algorithm for the fundamental matrix with a posteriori\n",
    "     enforcement of the singularity constraint (det(F)=0).\n",
    "     Does not include data normalization.\n",
    "\n",
    "     Reference: \"Multiple View Geometry\" (Hartley & Zisserman 2000), Sect. 10.1 page 262.\n",
    "\n",
    "     Input: point correspondences\n",
    "      - p1 np.ndarray(3,N): homogeneous coordinates of 2-D points in image 1\n",
    "      - p2 np.ndarray(3,N): homogeneous coordinates of 2-D points in image 2\n",
    "\n",
    "     Output:\n",
    "      - F np.ndarray(3,3) : fundamental matrix\n",
    "    \"\"\"\n",
    "\n",
    "    num_P = p1.shape[1]\n",
    "    A = np.zeros((num_P, 9))\n",
    "    for i in range(num_P):\n",
    "        A[i, :] = np.kron(p1[:, i], p2[:, i]).T\n",
    "    U, sigma, VT = np.linalg.svd(A, full_matrices=True)\n",
    "    F = VT.T[:, -1].reshape(3, 3)\n",
    "    U_F, sigma_F, VT_F = np.linalg.svd(F, full_matrices=True)\n",
    "    sigma_F[2] = 0\n",
    "    F_mod = U_F @ np.diag(sigma_F) @ VT_F\n",
    "    \n",
    "    return F_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273d8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fundamentalEightPointNormalized(p1, p2):\n",
    "    \"\"\" Normalized Version of the 8 Point algorith\n",
    "     Input: point correspondences\n",
    "      - p1 np.ndarray(3,N): homogeneous coordinates of 2-D points in image 1\n",
    "      - p2 np.ndarray(3,N): homogeneous coordinates of 2-D points in image 2\n",
    "\n",
    "     Output:\n",
    "      - F np.ndarray(3,3) : fundamental matrix\n",
    "    \"\"\"\n",
    "    p1_n, T1 = normalise2DPts(p1)\n",
    "    p2_n, T2 = normalise2DPts(p2)\n",
    "    \n",
    "    F_ = fundamentalEightPoint(p1_n, p2_n)\n",
    "    \n",
    "    F = T2.T @ F_ @T1\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79f1f6",
   "metadata": {},
   "source": [
    "## 数据读入 与函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62064ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dirname = os.path.dirname('/home/mullin/WorkSpace/CourseProject/3 VAMR/Exercise 6/python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66a3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = np.array(cv2.imread(dirname+'/data/0001.jpg'))\n",
    "img_2 = np.array(cv2.imread(dirname+'/data/0002.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504b0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([  [1379.74,   0,          760.35],\n",
    "                [    0,     1382.08,    503.41],\n",
    "                [    0,     0,          1 ]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accc5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load outlier-free point correspondences\n",
    "p1 = np.loadtxt(dirname+'/data/matches0001.txt')\n",
    "p2 = np.loadtxt(dirname+'/data/matches0002.txt')\n",
    "\n",
    "p1 = np.r_[p1, np.ones((1, p1.shape[1]))]\n",
    "p2 = np.r_[p2, np.ones((1, p2.shape[1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d52d20",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1427dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9336b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58a417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442003f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4cebf8e",
   "metadata": {},
   "source": [
    "## estimate Essential Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46fa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateEssentialMatrix(p1, p2, K1, K2):\n",
    "    \"\"\" estimates the essential matrix given matching point coordinates,\n",
    "        and the camera calibration K\n",
    "\n",
    "     Input: point correspondences\n",
    "      - p1 np.ndarray(3,N): homogeneous coordinates of 2-D points in image 1\n",
    "      - p2 np.ndarray(3,N): homogeneous coordinates of 2-D points in image 2\n",
    "      - K1 np.ndarray(3,3): calibration matrix of camera 1\n",
    "      - K2 np.ndarray(3,3): calibration matrix of camera 2\n",
    "\n",
    "     Output:\n",
    "      - E np.ndarray(3,3) : fundamental matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    F = fundamentalEightPointNormalized(p1,p2)\n",
    "    \n",
    "    E = K2.T @ F @ K1\n",
    "    \n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2affcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca630dc",
   "metadata": {},
   "source": [
    "## Function：DecomposeEMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f29447bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomposeEssentialMatrix(E):\n",
    "    \"\"\" Given an essential matrix, compute the camera motion, i.e.,  R and T such\n",
    "     that E ~ T_x R\n",
    "     \n",
    "     Input:\n",
    "       - E(3,3) : Essential matrix\n",
    "\n",
    "     Output:\n",
    "       - R(3,3,2) : the two possible rotations\n",
    "       - u3(3,1)   : a vector with the translation information\n",
    "    \"\"\"\n",
    "    \n",
    "    W = np.array([[0, -1, 0],\n",
    "                  [1,  0,  0],\n",
    "                  [0,  0,  1 ]] )\n",
    "    \n",
    "    U, sigma, VT = np.linalg.svd(E, full_matrices=True)\n",
    "    \n",
    "    if (np.linalg.det(U @ W @ VT) > 0):   \n",
    "        R[:,:,0] = U @ W @ VT\n",
    "    else:\n",
    "        R[:,:,0] = - U @ W @ VT\n",
    "    \n",
    "    if (np.linalg.det(U @ W.T @ VT) > 0):\n",
    "        R[:,:,1] = U @ W.T @ VT\n",
    "    else:\n",
    "        R[:,:,1] = - U @ W.T @ VT\n",
    "    \n",
    "    u3 = U[:,2]\n",
    "    \n",
    "    if np.linalg.norm(u3) != 0:\n",
    "        u3 /= np.linalg.norm(u3)\n",
    "    \n",
    "    return R, u3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7363ba",
   "metadata": {},
   "source": [
    "### test for decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35561e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "    W = np.array([[0, -1, 0],\n",
    "                  [1,  0,  0],\n",
    "                  [0,  0,  1 ]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a379ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sigma, VT = np.linalg.svd(E, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ba52d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.97431323,  0.00249371,  0.22518326])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ec5d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.66560148e-01,  2.50368550e-04,  2.56439890e-01],\n",
       "       [ 3.56035084e-04,  9.99999870e-01,  3.65624889e-04],\n",
       "       [ 2.56439765e-01, -4.44700045e-04,  9.66560112e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U @ W @ VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "382b465d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.81051429e-01, -4.43919147e-03, -1.93696639e-01],\n",
       "       [ 4.62877772e-03, -9.99989149e-01, -5.26213051e-04],\n",
       "       [ 1.93692201e-01,  1.41282075e-03, -9.81061331e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U @ W.T @ VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ae63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.zeros([3,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a77f1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.linalg.det(U @ W @ VT) > 0):\n",
    "    \n",
    "    R[:,:,0] = U @ W @ VT\n",
    "else:\n",
    "    R[:,:,0] = - U @ W @ VT\n",
    "    \n",
    "if (np.linalg.det(U @ W.T @ VT) > 0):\n",
    "    \n",
    "    R[:,:,1] = U @ W.T @ VT\n",
    "else:\n",
    "    R[:,:,1] = - U @ W.T @ VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "596a2f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "350ef503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9999999999999999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(U @ W @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a7a49e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9999999999999999"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(U @ W.T @ VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb07a0",
   "metadata": {},
   "source": [
    "## Funtion：disambiguate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguateRelativePose(Rots,u3,points0_h,points1_h,K1,K2):\n",
    "    \"\"\" DISAMBIGUATERELATIVEPOSE- finds the correct relative camera pose (among\n",
    "     four possible configurations) by returning the one that yields points\n",
    "     lying in front of the image plane (with positive depth).\n",
    "\n",
    "     Arguments:\n",
    "       Rots -  3x3x2: the two possible rotations returned by decomposeEssentialMatrix\n",
    "       u3   -  a 3x1 vector with the translation information returned by decomposeEssentialMatrix\n",
    "       p1   -  3xN homogeneous coordinates of point correspondences in image 1\n",
    "       p2   -  3xN homogeneous coordinates of point correspondences in image 2\n",
    "       K1   -  3x3 calibration matrix for camera 1\n",
    "       K2   -  3x3 calibration matrix for camera 2\n",
    "\n",
    "     Returns:\n",
    "       R -  3x3 the correct rotation matrix\n",
    "       T -  3x1 the correct translation vector\n",
    "\n",
    "       where [R|t] = T_C2_C1 = T_C2_W is a transformation that maps points\n",
    "       from the world coordinate system (identical to the coordinate system of camera 1)\n",
    "       to camera 2.\n",
    "    \"\"\"\n",
    "    M1 = K1 @ np.c_[np.eye(3), np.zeros((3,1))]\n",
    "    M2 = np.zeros((3,4,4))\n",
    "    M2[:,:,0] = K2 @ np.c_[Rots[:,:,0], u3]\n",
    "    M2[:,:,1] = K2 @ np.c_[Rots[:,:,1], u3]\n",
    "    M2[:,:,2] = K2 @ np.c_[Rots[:,:,0], -u3]\n",
    "    M2[:,:,3] = K2 @ np.c_[Rots[:,:,1], -u3]\n",
    "    \n",
    "    linearTriangulation()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32fe42",
   "metadata": {},
   "source": [
    "### Test for disambiguate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af1f4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = np.c_[np.eye(3), np.zeros((3,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cbdf348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d55cdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b82bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = np.zeros((3,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c582121",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2[:,:,0] = np.c_[Rots[:,:,0], u3]\n",
    "M2[:,:,1] = np.c_[Rots[:,:,1], u3]\n",
    "M2[:,:,2] = np.c_[Rots[:,:,0], -u3]\n",
    "M2[:,:,3] = np.c_[Rots[:,:,1], -u3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ab012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1c0ac80",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6fc9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\n",
      " [[-1.82281364e-03  7.17735511e-01 -8.66493166e-03]\n",
      " [-1.00053090e-01  7.57028808e-03 -3.10523987e+00]\n",
      " [-6.77887209e-03  3.10538322e+00 -3.10327163e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Estimate the essential matrix E using the 8-point algorithm\n",
    "E = estimateEssentialMatrix(p1, p2, K, K);\n",
    "print(\"E:\\n\", E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87fdde9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relative camera positions (R,T) from the essential matrix\n",
    "# Obtain extrinsic parameters (R,t) from E\n",
    "Rots, u3 = decomposeEssentialMatrix(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disambiguate among the four possible configurations\n",
    "R_C2_W,T_C2_W = disambiguateRelativePose(Rots, u3, p1, p2, K, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f77033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangulate a point cloud using the final transformation (R,T)\n",
    "M1 = K @ np.eye(3,4)\n",
    "M2 = K @ np.c_[R_C2_W, T_C2_W]\n",
    "P = linearTriangulation(p1, p2, M1, M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    " Visualize the 3-D scene\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "\n",
    "# R,T should encode the pose of camera 2, such that M1 = [I|0] and M2=[R|t]\n",
    "\n",
    "# P is a [4xN] matrix containing the triangulated point cloud (in\n",
    "# homogeneous coordinates), given by the function linearTriangulation\n",
    "ax.scatter(P[0,:], P[1,:], P[2,:], marker = 'o')\n",
    "\n",
    "# Display camera pose\n",
    "drawCamera(ax, np.zeros((3,)), np.eye(3), length_scale = 2)\n",
    "ax.text(-0.1,-0.1,-0.1,\"Cam 1\")\n",
    "\n",
    "center_cam2_W = -R_C2_W.T @ T_C2_W\n",
    "drawCamera(ax, center_cam2_W, R_C2_W.T, length_scale = 2)\n",
    "ax.text(center_cam2_W[0]-0.1, center_cam2_W[1]-0.1, center_cam2_W[2]-0.1,'Cam 2')\n",
    "\n",
    "# Display matched points\n",
    "ax = fig.add_subplot(1,3,2)\n",
    "ax.imshow(img_1)\n",
    "ax.scatter(p1[0,:], p1[1,:], color = 'y', marker='s')\n",
    "ax.set_title(\"Image 1\")\n",
    "\n",
    "ax = fig.add_subplot(1,3,3)\n",
    "ax.imshow(img_2)\n",
    "ax.scatter(p2[0,:], p2[1,:], color = 'y', marker='s')\n",
    "ax.set_title(\"Image 2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e99450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:VAMR]",
   "language": "python",
   "name": "conda-env-VAMR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
